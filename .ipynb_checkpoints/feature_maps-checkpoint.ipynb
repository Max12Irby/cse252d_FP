{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets.coco import CocoDetection\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load a pre-trained ResNet model\n",
    "resnet = models.resnet50(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer4.2.bn2.running_var: torch.Size([512])\n",
      "layer4.2.bn2.num_batches_tracked: torch.Size([])\n",
      "layer4.2.conv3.weight: torch.Size([2048, 512, 1, 1])\n",
      "layer4.2.bn3.weight: torch.Size([2048])\n",
      "layer4.2.bn3.bias: torch.Size([2048])\n",
      "layer4.2.bn3.running_mean: torch.Size([2048])\n",
      "layer4.2.bn3.running_var: torch.Size([2048])\n",
      "layer4.2.bn3.num_batches_tracked: torch.Size([])\n",
      "fc.weight: torch.Size([1000, 2048])\n",
      "fc.bias: torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([f'{layer}: {resnet.state_dict()[layer].shape}' for layer in list(resnet.state_dict())[-10:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/COCO-2017/anno2017/instances_train2017.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 3\u001b[0m coco_train_dataset, coco_val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_train_val_COCO\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UCSD/Spring 2024/Advanced CV/cse252d_FP/utils.py:11\u001b[0m, in \u001b[0;36mload_train_val_COCO\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_train_val_COCO\u001b[39m():\n\u001b[1;32m      8\u001b[0m     transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m      9\u001b[0m     transforms\u001b[39m.\u001b[39mToTensor()])\n\u001b[0;32m---> 11\u001b[0m     coco_train_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mCocoDetection(root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/datasets/COCO-2017/train2017\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m     12\u001b[0m                                       annFile\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/datasets/COCO-2017/anno2017/instances_train2017.json\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m                                       transform\u001b[39m=\u001b[39;49mtransform)\n\u001b[1;32m     15\u001b[0m     coco_val_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mCocoDetection(root\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/datasets/COCO-2017/val2017\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     16\u001b[0m                                       annFile\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/datasets/COCO-2017/anno2017/instances_val2017.json\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m                                       transform\u001b[39m=\u001b[39mtransform)\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m coco_train_dataset, coco_val_dataset\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/OBEG/lib/python3.9/site-packages/torchvision/datasets/coco.py:33\u001b[0m, in \u001b[0;36mCocoDetection.__init__\u001b[0;34m(self, root, annFile, transform, target_transform, transforms)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transforms, transform, target_transform)\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpycocotools\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcoco\u001b[39;00m \u001b[39mimport\u001b[39;00m COCO\n\u001b[0;32m---> 33\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoco \u001b[39m=\u001b[39m COCO(annFile)\n\u001b[1;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mids \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39msorted\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoco\u001b[39m.\u001b[39mimgs\u001b[39m.\u001b[39mkeys()))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/OBEG/lib/python3.9/site-packages/pycocotools/coco.py:81\u001b[0m, in \u001b[0;36mCOCO.__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloading annotations into memory...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     80\u001b[0m tic \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 81\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(annotation_file, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     82\u001b[0m     dataset \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m     83\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mtype\u001b[39m(dataset)\u001b[39m==\u001b[39m\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mannotation file format \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m not supported\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(dataset))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/COCO-2017/anno2017/instances_train2017.json'"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "coco_train_dataset, coco_val_dataset = load_train_val_COCO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7968b9cebb39c84253177e8a040e5c27a79f0c60db4a0e834a2284c4250f26ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
